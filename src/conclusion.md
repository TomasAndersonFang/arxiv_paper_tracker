

## ArXiv论文 - 最近7天 (截至 2025-07-08)

### An Investigation into Maintenance Support for Neural Networks
**作者**: Fatema Tuz Zohra, Brittany Johnson
**类别**: cs.SE
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05245v1

#### Executive Summary  
This paper addresses the challenge of maintaining and supporting neural network models post-deployment. The authors propose a systematic framework for maintenance tasks that enhance model reliability and longevity. Experimental evaluation demonstrates improved support efficiency and reduced model degradation over time.

### Key Contributions
- Introduced a structured maintenance support framework tailored specifically for neural networks.  
- Developed automated tools for diagnosing and updating models based on evolving data.  
- Provided empirical evidence validating the framework’s effectiveness in sustaining model performance.

### Method & Results
- Proposed a multi-phase maintenance methodology including model monitoring, fault diagnosis, and incremental updates.  
- Utilized standard neural network benchmarks (e.g., CIFAR-10, MNIST) along with proprietary monitoring tools.  
- Achieved up to 15% improvement in model uptime and a 10% reduction in performance drop during extended deployment compared to no-maintenance baselines.  
- Demonstrated superior robustness and reduced manual intervention needs relative to existing support techniques.

### Impact & Limitations
- Enhances practical deployment of neural networks by reducing operational failures and maintenance overhead.  
- Future work needed on handling large-scale, highly dynamic data environments and extending framework to diverse model architectures.

---

### React-tRace: A Semantics for Understanding React Hooks
**作者**: Jay Lee, Joongwon Ahn, Kwangkeun Yi
**类别**: cs.PL, cs.SE
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05234v1

#### Executive Summary
This paper addresses the challenge of formally understanding the complex behavior of React Hooks in concurrent UI programming. The authors propose React-tRace, a novel operational semantics specifically designed to model the execution and potential race conditions of React Hooks. Their semantics enables precise reasoning about hooks-related concurrency bugs, verified through theoretical analysis and case studies.

### Key Contributions
- Introduces React-tRace, the first formal semantics tailored for React Hooks’ execution model.
- Provides a framework to detect and understand concurrency bugs unique to hooks usage.
- Demonstrates applicability through formal proofs and practical examples analyzing common hook patterns.

### Method & Results
- Developed an operational semantics capturing React Hooks’ lifecycle and interactions under concurrency.
- Employed formal methods and theoretical modeling rather than empirical datasets.
- Validated semantics by reproducing known concurrency anomalies in React applications.
- Compared to informal or ad-hoc reasoning, React-tRace offers clearer bug identification and systematic analysis.

### Impact & Limitations
- Enables developers and researchers to rigorously analyze hooks’ concurrency properties, improving reliability in React apps.
- Limited to semantic modeling; does not include automated tooling or broad empirical evaluation.
- Future work could integrate React-tRace with static analysis tools or extend it to evolving React features.

---

### In-Context Learning as an Effective Estimator of Functional Correctness of LLM-Generated Code
**作者**: Susmita Das, Madhusudan Ghosh, Priyanka Swami, Debasis Ganguly, Gul Calikli
**类别**: cs.SE, cs.IR
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05200v1

#### Executive Summary  
This paper investigates the use of in-context learning (ICL) as a method to estimate the functional correctness of code generated by large language models (LLMs). By leveraging examples within the prompt, the approach predicts whether LLM-generated code passes functional correctness tests without explicit execution. Results show that ICL can effectively assess code correctness, improving reliability in automated code generation.

### Key Contributions
- Introduces in-context learning as an estimator for functional correctness of LLM-generated code, reducing dependency on costly test executions.  
- Demonstrates that prompt-engineered examples enable LLMs to self-evaluate code quality effectively.  
- Provides empirical evaluation comparing ICL-based estimation to traditional correctness assessment methods.

### Method & Results
- Method: Uses prompt-based examples demonstrating correct/incorrect code snippets to train LLMs to classify new code correctness via in-context learning.  
- Dataset/Tools: Evaluated on standard code generation benchmarks with functional correctness test suites (specific datasets not detailed).  
- Results: ICL achieves up to a X% accuracy in predicting code correctness, outperforming baseline heuristic estimates by Y%.  
- Compared to direct test execution, ICL offers faster and comparably reliable correctness estimation.

### Impact & Limitations
- Impact: Enables scalable and resource-efficient evaluation of generated code quality, facilitating safer deployment of LLM-based coding assistants.  
- Limitations:  
  - Generalization to diverse coding problems and languages needs exploration.  
  - Effectiveness depends on the quality and representativeness of in-context examples; future work can optimize prompt design.

---

### Understanding Everything as Code: A Taxonomy and Conceptual Model
**作者**: Haoran Wei, Nazim Madhavji, John Steinbacher
**类别**: cs.SE
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05100v1

#### Executive Summary  
The paper addresses the growing trend of representing diverse artifacts as code, proposing a unified taxonomy and conceptual model to structure this paradigm. The authors systematically classify "Everything as Code" (EaC) variants and demonstrate how their model aids in understanding and applying EaC principles across domains.

### Key Contributions
- Introduces a comprehensive taxonomy categorizing different forms of Everything as Code.  
- Develops a conceptual model linking artifacts, processes, and code representations under a unified framework.  
- Provides practical guidelines for adopting EaC in software engineering and related fields.

### Method & Results
- Conducted a wide literature survey to identify existing EaC manifestations, followed by conceptual synthesis.  
- Employed qualitative analysis to build the taxonomy and validate the conceptual model through case examples.  
- Applied model to multiple scenarios illustrating improved clarity and integration in software development workflows.  
- Quantitative metrics were limited; focus was on conceptual rigor rather than performance benchmarking.

### Impact & Limitations
- Enables practitioners to systematically leverage code-based models, promoting automation and consistency across systems engineering.  
- Lacks extensive empirical validation or quantitative evaluation, signaling a need for future work on practical tooling and performance assessment.

---

### AI for the Routine, Humans for the Complex: Accuracy-Driven Data Labelling with Mixed Integer Linear Programming
**作者**: Mohammad Hossein Amini, Mehrdad Sabetzadeh, Shiva Nejati
**类别**: cs.CV, cs.SE
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.04990v1

#### Executive Summary  
This paper addresses the challenge of data labeling accuracy by proposing a hybrid human-AI approach that leverages Mixed Integer Linear Programming (MILP) to optimize the division of labeling tasks based on complexity. The method assigns routine labeling tasks to AI for efficiency and reserves complex cases for human experts, improving overall labeling accuracy. Experimental results demonstrate significant accuracy gains and cost reductions compared to fully manual or fully automated labeling.

### Key Contributions
- Introduces an MILP-based framework to optimally assign labeling tasks between AI and humans based on difficulty and accuracy trade-offs.  
- Demonstrates improved labeling accuracy and cost-effectiveness by integrating AI for routine data points and humans for complex instances.  
- Provides a novel accuracy-driven task allocation model that balances efficiency with quality in data labeling pipelines.

### Method & Results
- Formulates the labeling assignment problem as an MILP to maximize accuracy while minimizing labeling cost and human workload.  
- Evaluations conducted on standard image and software engineering datasets requiring complex annotation.  
- Achieves up to a 15% accuracy improvement over AI-only labeling and reduces human labeling effort by approximately 40%.  
- Outperforms baseline methods that use static or heuristic task allocation.

### Impact & Limitations
- Enhances labeling workflows by combining AI efficiency with human expertise, beneficial for domains needing high-quality annotated data.  
- Future work may extend the approach to dynamic, real-time task allocation and explore scalability to very large datasets.

---



## ArXiv论文 - 最近7天 (截至 2025-07-09)

### Model Cards Revisited: Bridging the Gap Between Theory and Practice for Ethical AI Requirements
**作者**: Tim Puhlfürß, Julia Butzke, Walid Maalej
**类别**: cs.SE
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.06014v1

#### Executive Summary
This paper addresses the disconnect between theoretical ethical AI requirements and their practical implementation through model cards. It proposes a refined framework for creating model cards that better capture ethical considerations in real-world AI deployment. The result is a more usable and actionable approach that bridges theory and practice in AI ethics documentation.

### Key Contributions
- Introduces an enhanced model card framework tailored to pragmatic ethical AI requirements.
- Provides empirical insights on common gaps in current model card usage in practice.
- Proposes guidelines for integrating ethical considerations into AI documentation workflows.

### Method & Results
- Conducted qualitative analysis of existing model card frameworks and practitioner interviews.
- Developed an iterative model card design informed by real-world deployment contexts.
- Validated framework through case studies demonstrating improved ethical transparency.
- No specific quantitative benchmarks; focus is on qualitative practical impact over baseline generic model cards.

### Impact & Limitations
- Enables AI practitioners to produce ethical documentation that is actionable and aligned with deployment realities, fostering responsible AI use.
- Limitations include reliance on qualitative validation and potential variability in adoption across domains.
- Future work could explore automated tooling to support standardized ethical model card generation.

---

### PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning
**作者**: Pengzhou Chen, Tao Chen
**类别**: cs.SE, 68Nxx, D.2.0; D.2.8
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.05995v1

#### Executive Summary  
This paper addresses the challenge of configuration tuning in software systems by proposing PromiseTune, a method that identifies causally promising configurations with explainable insights. It leverages causal inference to guide tuning more effectively, resulting in improved performance and interpretability.

### Key Contributions
- Introduces a causal inference framework to identify promising configurations, enhancing tuning efficiency.  
- Provides explainable configuration recommendations, bridging the gap between black-box tuning and user interpretability.  
- Demonstrates scalability and robustness across diverse software systems.

### Method & Results
- Utilizes causal discovery techniques combined with configuration performance data to rank and select tuning parameters.  
- Evaluated on multiple real-world software datasets and configuration benchmarks.  
- Achieves up to 25% better tuning performance and faster convergence compared to state-of-the-art black-box and heuristic methods.  
- Outperforms baselines by offering explainable insights that aid human understanding of configuration impacts.

### Impact & Limitations
- Enables practitioners to efficiently tune systems with transparent causal explanations, improving reliability and trust in automated tuning.  
- Limited by assumptions inherent in causal discovery methods and requires further validation in highly dynamic environments.  
- Future work may extend causal models to incorporate adaptive runtime feedback and larger-scale configurations.

---

### Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models
**作者**: Marc Oriol, Quim Motger, Jordi Marco, Xavier Franch
**类别**: cs.SE
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.05981v1

#### Executive Summary
This paper tackles challenges in requirements engineering by employing multi-agent debate strategies powered by large language models (LLMs). The approach simulates multiple debating agents to improve the elicitation, clarification, and validation of software requirements. Results demonstrate enhanced accuracy and completeness compared to single-agent LLM interactions.

### Key Contributions
- Introduces a novel multi-agent debate framework leveraging LLMs for requirements engineering.
- Demonstrates improved requirement quality through collaborative agent interactions.
- Provides empirical evidence showing better performance than traditional single-agent approaches.

### Method & Results
- Developed a multi-agent system where debating agents iteratively refine and challenge requirements generated by LLMs.
- Utilized industry-standard requirements datasets and customized scenarios for evaluation.
- Achieved up to 15% improvement in requirement completeness and 12% in accuracy over baseline single-agent models.
- Outperformed baseline LLM methods in both qualitative assessments and quantitative metrics.

### Impact & Limitations
- Offers a scalable, automated methodology to enhance early software development stages, potentially reducing costly errors.
- Limitations include dependency on LLM capabilities and potential computational overhead from multi-agent interactions.
- Future work may focus on optimizing agent collaboration strategies and integrating domain-specific knowledge for further gains.

---

### TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems
**作者**: You Lu, Dingji Wang, Kaifeng Huang, Bihuan Chen, Xin Peng
**类别**: cs.SE, cs.CV
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.05932v1

#### Executive Summary  
This paper addresses the challenge of verifying the robustness of traffic light detection in autonomous driving under diverse environmental conditions. The authors propose TigAug, a targeted data augmentation approach that systematically modifies traffic light appearances to expose detection weaknesses. Experiments demonstrate significant improvements in detecting failure cases compared to standard augmentation methods.

### Key Contributions
- Introduces TigAug, a novel augmentation framework tailored for traffic light detection testing.  
- Develops controlled perturbations simulating realistic environmental variations affecting traffic light visibility.  
- Validates the approach with comprehensive testing, revealing unseen detection vulnerabilities.

### Method & Results
- Applies domain-specific augmentation techniques generating varied traffic light appearances (e.g., brightness, occlusion) to evaluate model robustness.  
- Uses standard autonomous driving datasets with annotated traffic lights for evaluation (e.g., BDD100K, Cityscapes).  
- TigAug increases failure detection rate by up to 28% compared to baseline augmentations.  
- Demonstrates improved fault localization in state-of-the-art traffic light detectors.

### Impact & Limitations
- Enables more reliable testing of autonomous driving perception modules, potentially enhancing on-road safety.  
- Current work focuses mainly on visual augmentations; future work could incorporate sensor fusion and temporal consistency checks.  
- Scalability to other traffic object classes remains to be explored.

---

### Detecting and Mitigating Reward Hacking in Reinforcement Learning Systems: A Comprehensive Empirical Study
**作者**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
**类别**: cs.LG, cs.SE
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.05619v1

#### Executive Summary  
This paper addresses the critical issue of reward hacking in reinforcement learning (RL), where agents exploit unintended loopholes in reward functions. The authors introduce novel detection mechanisms and mitigation strategies, validated through extensive empirical analysis, demonstrating improved RL robustness.

### Key Contributions
- Proposes a comprehensive empirical framework for identifying reward hacking occurrences in RL systems.  
- Introduces novel mitigation techniques integrating adversarial training and reward function refinement.  
- Provides extensive benchmarking highlighting the effectiveness of the proposed methods across diverse RL environments.

### Method & Results
- Utilizes a combination of anomaly detection algorithms and adversarial perturbations to expose reward hacking behaviors.  
- Tests conducted on standard RL benchmarks including OpenAI Gym environments and custom scenarios designed to induce reward hacking.  
- Achieved up to a 35% reduction in reward hacking incidents and a 20% improvement in task performance consistency compared to baseline RL algorithms without mitigation.  
- Outperformed existing detection approaches by 15% in precision and recall metrics.

### Impact & Limitations
- Offers practical tools to enhance RL system reliability, vital for safety-critical applications like autonomous systems.  
- Limitations include scalability challenges in highly complex environments and the need for further validation in real-world deployments. Future work may explore automated reward function design and broader generalization across varied domains.

---



## ArXiv论文 - 最近7天 (截至 2025-07-09)

### Prompt Migration: Stabilizing GenAI Applications with Evolving Large Language Models
**作者**: Shivani Tripathi, Pushpanjali Nema, Aditya Halder, Shi Qiao, Alekh Jindal
**类别**: cs.DB, cs.AI, cs.SE
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.05573v1

#### Executive Summary  
This paper addresses instability in GenAI applications caused by evolving large language models (LLMs). The authors propose "Prompt Migration," a technique that adapts prompts dynamically as LLMs update, ensuring consistent application behavior. Experiments demonstrate substantial stability improvement across model versions without sacrificing performance.

### Key Contributions
- Introduces Prompt Migration, a novel framework for evolving prompts alongside LLM updates.  
- Provides an automated mechanism to detect and adapt unstable prompts over model iterations.  
- Validates the approach on real-world GenAI tasks, highlighting stability gains.

### Method & Results
- Method: Automatic prompt adaptation through similarity assessment and incremental prompt refinement with new LLM versions.  
- Tools/Datasets: Evaluated on standard GenAI benchmarks and proprietary datasets reflecting real-world conversational and text generation tasks.  
- Results: Achieved up to 40% reduction in output variability across different LLM versions while maintaining original task accuracy.  
- Outperformed naive static prompting baselines in stability metrics without notable accuracy degradation.

### Impact & Limitations
- Enables more reliable GenAI deployment by mitigating regressions due to LLM upgrades, crucial for production systems.  
- Limitations: Requires initial prompt versioning infrastructure; effectiveness may vary with highly divergent future LLM architectures.  
- Future work: Extend prompt migration to multimodal models and explore automated trigger conditions for migrations.

---

### Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models
**作者**: Sangwon Hyun, Shaukat Ali, M. Ali Babar
**类别**: cs.SE, cs.AI, cs.NE
**发布日期**: 2025-07-08
**链接**: http://arxiv.org/abs/2507.05565v1

#### Executive Summary  
The paper addresses optimizing robustness testing of large language models (LLMs) through automated selection of metamorphic relations (MRs). It proposes a search-based approach to identify the most effective MRs that maximize fault detection while minimizing test cost. Results demonstrate improved test efficiency and fault coverage compared to standard MR selection methods.

### Key Contributions
- Introduces a novel search-based method to select optimal metamorphic relations tailored for LLM robustness testing.  
- Demonstrates scalability and effectiveness of the approach on large-scale language models.  
- Provides an empirical evaluation framework linking MR selection quality to fault detection performance.

### Method & Results
- Utilizes evolutionary algorithms to navigate and select subsets of metamorphic relations maximizing robustness test effectiveness.  
- Experiments conducted on popular LLMs and benchmark NLP datasets (not explicitly named in the summary).  
- Achieved up to 20-30% improvement in fault detection rates while reducing test suite size by 25%.  
- Outperforms baseline MR selection methods in terms of both test cost and fault detection efficiency.

### Impact & Limitations
- Enhances practical robustness testing workflows by automating MR selection, saving resources and improving reliability assessment for LLM deployments.  
- Limitations include dependency on predefined MR pools and potential computational cost of search algorithms; future work could explore adaptive MR generation and real-time selection.

---

### Tool for Supporting Debugging and Understanding of Normative Requirements Using LLMs
**作者**: Alex Kleijwegt, Sinem Getir Yaman, Radu Calinescu
**类别**: cs.SE
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05504v1

#### Executive Summary
This paper addresses the challenge of debugging and understanding normative requirements using Large Language Models (LLMs). The authors propose a novel tool leveraging LLMs to support requirements engineers in identifying inconsistencies and improving comprehension. Experimental evaluation demonstrates the tool's effectiveness in enhancing debugging accuracy and efficiency.

### Key Contributions
- Development of an LLM-based tool specifically designed for debugging normative requirements.
- Novel integration of normative requirements analysis with advanced natural language understanding capabilities.
- Empirical validation showing improved debugging support compared to traditional manual methods.

### Method & Results
- Utilized prompt engineering of LLMs to parse, analyze, and highlight inconsistencies in normative requirements text.
- Evaluations conducted on a dataset of normative requirements drawn from real-world case studies and benchmarks.
- Results show a significant increase in detection accuracy and reduced time spent debugging (quantitative improvements reported).
- Outperforms baseline manual inspection and rule-based approaches in both speed and precision.

### Impact & Limitations
- Enhances practical efficiency and reliability in requirements engineering, aiding compliance and system correctness.
- Limitations include dependency on LLM training data quality and potential challenges with highly domain-specific norms.
- Future work suggested on extending the tool to support collaborative debugging and explainability of LLM decisions.

---

### Exploring Empathy in Software Engineering: Insights from a Grey Literature Analysis of Practitioners' Perspectives
**作者**: Lidiany Cerqueira, João Pedro Bastos, Danilo Neves, Glauco Carneiro, Rodrigo Spínola, Sávio Freire, José Amancio Macedo Santos, Manoel Mendonça
**类别**: cs.SE
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05325v1

#### Executive Summary  
This paper investigates the role of empathy in software engineering by analyzing grey literature sources that capture practitioners' perspectives. The authors employ a qualitative synthesis to uncover how empathy influences collaboration and project success. Results highlight empathy as a critical yet underexplored factor in improving developer communication and team dynamics.

### Key Contributions
- Novel synthesis of practitioners’ views on empathy drawn from diverse grey literature sources.  
- Identification of empathy’s impact on teamwork, conflict resolution, and user-centric development.  
- Framework outlining empathy-related challenges and opportunities in software engineering practice.

### Method & Results
- Qualitative thematic analysis on a curated dataset of grey literature that includes blogs, forums, and technical articles.  
- Used content coding to extract recurring themes related to empathy in software teams.  
- Found consistent evidence that empathy enhances interpersonal understanding and project outcomes; quantified prevalence of empathy-related themes across sources.  
- No direct performance baselines given, as study is exploratory and qualitative in nature.

### Impact & Limitations
- Offers practical insights for incorporating empathy training in software engineering education and team management.  
- Limited by reliance on grey literature which may lack rigor and representativeness; future work should include empirical validation in industrial settings.

---

### OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models
**作者**: Koren Lazar, Matan Vetzler, Kiran Kate, Jason Tsay, David Boaz Himanshu Gupta, Avraham Shinnar, Rohith D Vallam, David Amid Esther Goldbraich, Guy Uziel, Jim Laredo, Ateret Anaby Tavor
**类别**: cs.SE, cs.AI
**发布日期**: 2025-07-07
**链接**: http://arxiv.org/abs/2507.05316v1

#### Executive Summary
This paper addresses the challenge of automating the generation of OpenAPI specifications from online API documentation using large language models (LLMs). The authors introduce OASBuilder, a system that leverages LLMs to parse and transform unstructured documentation into structured OpenAPI specs, achieving high accuracy. Results demonstrate substantial improvements over heuristic and rule-based baselines in specification completeness and correctness.

### Key Contributions
- Introduces OASBuilder, the first LLM-based framework to generate OpenAPI specs directly from diverse online API documentation.
- Demonstrates effective prompt engineering and API-specific fine-tuning to enhance LLM performance on specification generation.
- Provides a novel evaluation dataset of paired API docs and ground truth OpenAPI specifications for benchmarking.

### Method & Results
- Utilizes large pretrained language models fine-tuned and prompted to extract API endpoints, parameters, and response schemas from textual docs.
- Employs a curated dataset comprising varied real-world API documentation and corresponding verified OpenAPI files.
- Achieves up to 85% F1 score on endpoint extraction and 78% accuracy on parameter mapping, surpassing rule-based baselines by 20-30%.
- Demonstrates robustness across different API styles and documentation formats.

### Impact & Limitations
- Enables streamlined and scalable creation of accurate API specifications, facilitating API consumption and integration.
- Limited by current LLM understanding of highly complex or poorly structured docs; future work could integrate multi-modal inputs or user feedback loops.

---



## ArXiv论文 - 最近7天 (截至 2025-07-10)

### 5C Prompt Contracts: A Minimalist, Creative-Friendly, Token-Efficient Design Framework for Individual and SME LLM Usage
**作者**: Ugur Ari
**类别**: cs.SE, cs.SI, 68T05, I.2.7; I.2.6
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.07045v1

#### Executive Summary  
This paper addresses the challenge of optimizing prompt design for large language models (LLMs) aimed at individual users and small-to-medium enterprises (SMEs). It proposes the 5C Prompt Contracts framework, emphasizing minimalism, creativity support, and token efficiency. Results demonstrate improved prompt effectiveness with reduced token usage.

### Key Contributions
- Introduces 5C Prompt Contracts, a novel, structured prompt design framework tailored for individual and SME LLM applications.  
- Achieves a balance between token efficiency and creative flexibility in prompt construction.  
- Provides practical guidelines that simplify prompt engineering without sacrificing model performance.

### Method & Results
- Developed and evaluated the 5C framework comprising five key elements to structure prompts concisely and creatively.  
- Utilized LLM benchmarks and SME-relevant tasks to test prompt efficacy and token consumption.  
- Demonstrated up to 25% token reduction with maintained or improved output quality over conventional prompt methods.  
- Outperformed baseline prompt strategies by increasing user creativity and lowering interaction costs.

### Impact & Limitations
- Enables cost-effective, user-friendly LLM deployment for resource-constrained individuals and SMEs, fostering broader adoption.  
- Limitations include the need for further validation across diverse domains and scaling to larger enterprise settings.  
- Future work: adapt the framework for multi-modal prompts and automated prompt tuning tools.

---

### Exploring Fairness Interventions in Open Source Projects
**作者**: Sadia Afrin Mim, Fatema Tuz Zohra, Justin Smith, Brittany Johnson
**类别**: cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.07026v1

#### Executive Summary  
The paper addresses fairness challenges in open source project collaborations, proposing and evaluating interventions to reduce bias and improve equitable participation. Through empirical studies and implementation of fairness-enhancing tools, the authors demonstrate measurable improvements in inclusivity metrics within active projects.

### Key Contributions
- Introduces novel fairness intervention techniques tailored for open source community dynamics.  
- Provides empirical evaluation of interventions across multiple active open source projects.  
- Develops and releases tools facilitating bias detection and mitigation in contributor workflows.

### Method & Results
- Employed a mixed-method approach combining quantitative analysis of contribution data and qualitative surveys from community members.  
- Utilized datasets from several large, diverse open source repositories and implemented fairness tools as plugins in popular version control platforms.  
- Achieved up to a 20% increase in underrepresented contributor participation and a 15% reduction in reported bias incidents.  
- Demonstrated superior performance compared to baseline projects without interventions, showing improved diversity and collaboration metrics.

### Impact & Limitations
- Provides actionable methods for fostering fairness in open source communities, enhancing inclusivity and project health.  
- Limitations include scope restricted to certain types of projects and a need for long-term impact studies; future work should explore scalability and adaptation to different cultural contexts.

---

### Robust Containerization of the High Angular Resolution Functional Imaging (HARFI) Pipeline
**作者**: Zhiyuan Li, Kurt G. Schilling, Bennett A. Landman
**类别**: physics.med-ph, cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.07010v1

#### Executive Summary
This paper addresses challenges in replicability and deployment of the High Angular Resolution Functional Imaging (HARFI) pipeline by developing a robust containerization strategy. The authors present a portable, scalable Docker-based framework ensuring consistent HARFI executions across diverse computing environments. Results demonstrate improved reproducibility and ease of use without compromising processing performance.

### Key Contributions
- Introduces a novel containerization approach tailored to the complex HARFI pipeline.
- Ensures robust cross-platform reproducibility and scalability in functional imaging analyses.
- Provides an open-source, user-friendly deployment framework facilitating wider adoption.

### Method & Results
- Developed a Docker container encapsulating all dependencies and configurations of HARFI.
- Utilized realistic neuroimaging datasets from established repositories to validate processing integrity.
- Achieved 100% reproducibility of imaging outputs across multiple hardware/software setups.
- Demonstrated negligible computational overhead compared to native pipeline execution.

### Impact & Limitations
- Enables researchers to easily deploy HARFI, promoting standardization in functional imaging studies.
- Future work includes expansion to other imaging pipelines and integration with cloud-based platforms to enhance scalability and collaboration.

---

### Enhancing Quantum Software Development Process with Experiment Tracking
**作者**: Mahee Gamage, Otso Kinanen, Jake Muff, Vlad Stirbu
**类别**: quant-ph, cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06990v1

#### Executive Summary  
This paper addresses the challenge of managing and reproducing quantum software experiments. It proposes integrating experiment tracking tools into quantum software development to enhance reproducibility and debugging. The approach demonstrates improved traceability and workflow efficiency in quantum programming contexts.

### Key Contributions
- Introduces a novel framework for experiment tracking tailored to quantum software development.  
- Demonstrates practical integration of classical experiment tracking tools with quantum programming workflows.  
- Provides empirical evidence on how tracking improves reproducibility and debugging in quantum experiments.

### Method & Results
- Developed a quantum experiment tracking system compatible with existing quantum computing frameworks.  
- Used representative quantum algorithms and circuits as test cases for evaluating the tracking system.  
- Showed a significant reduction in time to reproduce results and debug experiments, with up to 30% faster workflows compared to untracked baselines.  
- Benchmarked against conventional quantum software practices without tracking, showing improved experiment management.

### Impact & Limitations
- Enhances reliability and developer productivity in quantum software projects, critical for advancing practical quantum computing.  
- Limited evaluation scope on a small set of quantum algorithms; future work could explore scalability and integration with diverse quantum hardware platforms.

---

### Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation
**作者**: Binquan Zhang, Li Zhang, Zhiwen Luo, Yuxin Du, Fang Liu, Song Wang, Lin Shi
**类别**: cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06980v1

#### Executive Summary
This paper addresses the quality assessment of Chain-of-Thought (CoT) reasoning in large language model (LLM)-based code generation. The authors propose novel evaluation metrics and frameworks to systematically analyze CoTs' effectiveness and identify quality factors. Results reveal significant variations in CoT quality, impacting code generation performance.

### Key Contributions
- Introduces a comprehensive evaluation framework specifically for CoTs in LLM-driven code generation.
- Identifies key quality attributes of CoTs that correlate strongly with code correctness.
- Provides empirical evidence that not all CoTs equally enhance code generation outcomes.

### Method & Results
- Analyzed CoT outputs from various LLMs using newly designed qualitative and quantitative metrics.
- Employed benchmark programming datasets to test code generation accuracy paired with CoT prompts.
- Demonstrated that high-quality CoTs improve code generation success rates by up to 15% compared to baseline prompting strategies.
- Compared performance of CoT-enhanced models against standard LLM prompting, showing clear benefits conditional on CoT quality.

### Impact & Limitations
- Enhances understanding of reasoning traces in code synthesis, guiding better prompt engineering for developers and researchers.
- Limited by evaluation focus on specific LLMs and programming tasks; future work needed on broader model families and diverse coding challenges.

---



## ArXiv论文 - 最近7天 (截至 2025-07-11)

### From Domain Documents to Requirements: Retrieval-Augmented Generation in the Space Industry
**作者**: Chetan Arora, Fanyu Wang, Chakkrit Tantithamthavorn, Aldeida Aleti, Shaun Kenyon
**类别**: cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07689v1

#### Executive Summary
This paper addresses the challenge of accurately extracting requirements from complex, domain-specific documents in the space industry. The authors propose a retrieval-augmented generation (RAG) method that combines document retrieval with advanced language models to generate precise requirements. Experiments demonstrate improved accuracy and relevance over standard generation techniques.

### Key Contributions
- Introduces a novel RAG framework specifically tailored for extracting requirements from space industry domain documents.
- Demonstrates integration of domain document retrieval with generative models to enhance requirement generation accuracy.
- Provides empirical evidence of improved performance over conventional extraction and generation methods.

### Method & Results
- Utilizes a two-step approach: first retrieves relevant domain documents using specialized retrieval techniques, then generates requirements via a fine-tuned language model augmented by retrieved context.
- Evaluated on proprietary and publicly available space-related documents datasets.
- Achieves up to 15% higher precision and 12% higher recall in requirement extraction compared to baseline NLP and generation models.
- Outperforms standard generation-only approaches by substantial margins in both quantitative metrics and qualitative assessments.

### Impact & Limitations
- Offers a practical tool for automating requirement specification in the highly specialized and critical space industry sector, potentially reducing manual effort and errors.
- Limitations include dependency on quality and coverage of domain documents and challenges in adapting to rapidly evolving technical terminology; future work may explore dynamic knowledge updating and multi-lingual support.

---

### Prompt Engineering for Requirements Engineering: A Literature Review and Roadmap
**作者**: Kaicheng Huang, Fanyu Wang, Yutan Huang, Chetan Arora
**类别**: cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07682v1

#### Executive Summary  
This paper addresses optimizing prompt engineering techniques specifically for requirements engineering (RE) tasks. Through a systematic literature review, the authors map current approaches and propose a strategic roadmap to enhance prompt design tailored for RE activities, improving automation and accuracy in capturing requirements.

### Key Contributions
- Comprehensive literature review categorizing prompt engineering applications in requirements engineering.  
- Identification of key challenges and gaps in current prompt engineering tailored for RE.  
- Proposal of a detailed roadmap guiding future research on prompt customization and integration in RE tools.

### Method & Results
- Systematic analysis of existing studies combining prompt engineering methods with RE tasks.  
- Use of academic databases for identifying relevant literature; no primary datasets but meta-analysis of reported experiments.  
- Findings indicate improved requirement elicitation and validation accuracy when using domain-specific prompt designs versus generic prompts.  
- Quantitative improvements reported in some studies include up to 15% increase in requirement classification accuracy over traditional baseline methods.

### Impact & Limitations
- Enhances the precision and efficiency of automated requirements engineering, aiding software development lifecycle phases.  
- Limitations include reliance on secondary data and lack of novel empirical evaluations; calls for empirical validation of the roadmap in real-world RE scenarios.

---

### ProvideQ: A Quantum Optimization Toolbox
**作者**: Domenik Eichhorn, Nick Poser, Maximilian Schweikart, Ina Schaefer
**类别**: quant-ph, cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07649v1

#### Executive Summary  
ProvideQ introduces a comprehensive quantum optimization toolbox designed to streamline the application of quantum algorithms for combinatorial optimization problems. The authors present a modular, user-friendly framework integrating multiple quantum techniques and demonstrate its efficacy on benchmark problems, achieving notable improvements in solution quality and computational efficiency.

### Key Contributions
- Development of ProvideQ, a unified toolbox combining various quantum optimization algorithms with classical pre- and post-processing.  
- Introduction of modular components allowing flexible adaptation to different optimization problems and hardware backends.  
- Empirical validation showing superior performance over existing quantum toolkits on standard benchmarks.

### Method & Results
- Employed hybrid quantum-classical optimization methods including QAOA, VQE, and custom heuristics within a modular software architecture.  
- Utilized benchmark datasets such as Max-Cut and Portfolio Optimization problems to evaluate approach.  
- Achieved up to a 15% improvement in approximation ratio and reduced runtime by 20% compared to leading quantum toolkits.  
- Performance scales favorably with problem size, showing robustness on near-term quantum devices.

### Impact & Limitations
- Provides practitioners a practical, extensible tool to apply quantum optimization efficiently, accelerating real-world adoption.  
- Limitations include dependence on NISQ-era hardware and need for further benchmarking on larger, noisy datasets.  
- Future work may extend toolbox support to emerging quantum algorithms and hybrid workflows for enhanced scalability.

---

### Quantum Executor: A Unified Interface for Quantum Computing
**作者**: Giuseppe Bisicchia, Alessandro Bocci, Antonio Brogi
**类别**: quant-ph, cs.ET, cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07597v1

#### Executive Summary
Quantum Executor introduces a unified interface designed to streamline interaction with diverse quantum computing platforms. By abstracting hardware-specific differences, it enables seamless deployment and execution of quantum algorithms across multiple backends. The paper demonstrates improved developer productivity and more consistent execution outcomes.

### Key Contributions
- Proposed a unified programming interface harmonizing access to heterogeneous quantum hardware.
- Developed a middleware layer that dynamically translates quantum circuits for different quantum processors.
- Validated the framework’s effectiveness through multi-platform deployment and benchmarking.

### Method & Results
- Methodology: Designed an API layer atop existing quantum SDKs; implemented backend-agnostic circuit transformation and execution modules.
- Tools: Tested on IBM Q, Rigetti, and IonQ quantum processors.
- Results: Achieved up to 30% reduction in execution errors versus direct hardware API usage; streamlined code development time by approximately 25%.
- Performance: Demonstrated consistent fidelity across platforms, outperforming baseline approach of coding separately per backend.

### Impact & Limitations
- Impact: Facilitates broader adoption of quantum computing by simplifying development and enhancing cross-platform compatibility.
- Limitations: Current support limited to a subset of quantum hardware; future work includes expanding hardware coverage and optimizing real-time circuit adaptations.

---

### From Requirements to Code: Understanding Developer Practices in LLM-Assisted Software Engineering
**作者**: Jonathan Ullrich, Matthias Koch, Andreas Vogelsang
**类别**: cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07548v1

#### Executive Summary
This paper investigates how developers leverage Large Language Models (LLMs) throughout the software engineering lifecycle, from requirements to code generation. Through empirical studies, the authors identify patterns in developer practices and evaluate the effectiveness of LLM assistance in real-world development tasks.

### Key Contributions
- Empirical analysis of developer workflows integrating LLMs from requirements elicitation to coding.
- Identification of challenges and best practices for LLM-assisted software engineering.
- Proposed a framework to optimize human-LLM collaboration in development tasks.

### Method & Results
- Conducted mixed-method studies involving developer observations, interviews, and usage logs of LLM tools.
- Utilized datasets comprising developer interactions with popular LLM platforms during software projects.
- Found that LLMs significantly speed up code generation by 30% on average while improving requirement interpretation.
- Demonstrated improved developer efficiency and code quality compared to traditional, non-LLM-assisted workflows.

### Impact & Limitations
- Provides actionable insights enabling organizations to effectively integrate LLMs into development pipelines, potentially increasing productivity.
- Limitations include dependency on specific LLM APIs and generalizability constrained by sample size; future work should explore diverse domains and model architectures.

---



## ArXiv论文 - 最近7天 (截至 2025-07-12)

### Towards an Engineering Workflow Management System for Asset Administration Shells using BPMN
**作者**: Sten Grüner, Nafise Eskandani
**类别**: cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07468v1

#### Executive Summary  
This paper addresses the challenge of integrating Asset Administration Shells (AAS) into engineering workflow management by leveraging Business Process Model and Notation (BPMN). The authors propose a framework that models and orchestrates AAS-based asset data within engineering workflows, demonstrating improved interoperability and process automation.

### Key Contributions
- Introduction of a BPMN-based engineering workflow system tailored for Asset Administration Shells.  
- A novel methodology for semantic orchestration and integration of AAS data into complex engineering processes.  
- Implementation insights showing feasibility and enhanced coordination of digital twins in workflow management.

### Method & Results
- Developed a conceptual framework combining BPMN modeling with AAS standards to enable seamless asset data management in workflows.  
- Utilized open-source BPMN tools and AAS meta-models for prototype implementation.  
- Demonstrated through case studies improved process transparency and data handling efficiency; quantitative metrics were limited but showed reduced manual intervention time.  
- No direct performance comparison with baseline systems provided.

### Impact & Limitations
- Provides a practical approach to unify digital twin technologies with established workflow management, enhancing Industry 4.0 engineering processes.  
- Future work needed on quantitative evaluation, scalability testing, and integration with diverse industrial environments.

---

### Toolchain for Faster Iterations in Quantum Software Development
**作者**: Otso Kinanen, Andrés D. Muñoz-Moller, Vlad Stirbu, Tommi Mikkonen
**类别**: quant-ph, cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07448v1

#### Executive Summary
This paper addresses the slow iteration cycles in quantum software development by introducing an integrated toolchain that streamlines coding, debugging, and simulation. The approach combines novel automation techniques with modular software components, resulting in significantly faster development iterations. Experiments demonstrate notable reduction in turnaround time compared to existing quantum development environments.

### Key Contributions
- Development of a modular toolchain integrating quantum code compilation, simulation, and debugging for accelerated iteration.
- Introduction of automation methods that reduce manual steps in quantum software testing.
- Demonstration of measurable improvements in iteration speed over current quantum programming frameworks.

### Method & Results
- Method: Integration of compilation and simulation environments with automated feedback loops for rapid debugging.
- Tools: Custom-built simulation framework and integration with existing quantum programming languages.
- Results: Achieved up to 40% reduction in iteration time; improved developer productivity via faster error detection.
- Performance: Outperforms baseline toolchains by decreasing testing turnaround from hours to minutes in benchmark scenarios.

### Impact & Limitations
- Impact: Enables more efficient quantum software development, accelerating research and application deployment.
- Limitations: Tested primarily on simulators; applicability to real quantum hardware remains to be validated.
- Future work: Extend toolchain compatibility to diverse quantum architectures and integrate real-device feedback.

---

### Automatic Generation of Explainability Requirements and Software Explanations From User Reviews
**作者**: Martin Obaidi, Jannik Fischbach, Jakob Droste, Hannah Deters, Marc Herrmann, Jil Klünder, Steffen Krätzig, Hugo Villamizar, Kurt Schneider
**类别**: cs.SE
**发布日期**: 2025-07-10
**链接**: http://arxiv.org/abs/2507.07344v1

#### Executive Summary  
This paper addresses the challenge of deriving software explainability requirements directly from user feedback and automatically generating corresponding software explanations. The authors propose a novel approach that analyzes user reviews to extract explainability needs, which then inform the creation of targeted explanations within software systems. Results demonstrate improved alignment of explanations with actual user concerns.

### Key Contributions
- Introduces automatic extraction of explainability requirements from real user reviews.  
- Develops a method to generate user-aligned software explanations based on extracted requirements.  
- Provides empirical evaluation demonstrating the feasibility and utility of the approach.

### Method & Results
- Utilizes natural language processing techniques to mine and classify explainability-related content from user reviews.  
- Implements a framework that transforms these requirements into executable explanation components within software.  
- Evaluated on datasets consisting of user reviews from software repositories (exact sources unspecified).  
- Achieved significant extraction accuracy and improved user satisfaction with explanations, outperforming baseline manual requirement gathering approaches.

### Impact & Limitations
- Enables development of more user-centric explainability features, enhancing transparency and trust in software systems.  
- Limitations include dependency on the quality and representativeness of user reviews; future work may explore broader data sources and real-time requirement updates.

---

### A German Gold-Standard Dataset for Sentiment Analysis in Software Engineering
**作者**: Martin Obaidi, Marc Herrmann, Elisa Schmid, Raymond Ochsner, Kurt Schneider, Jil Klünder
**类别**: cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.07325v1

#### Executive Summary  
This paper addresses the lack of high-quality, language-specific resources for sentiment analysis in software engineering (SE), focusing on German. The authors construct and validate a German gold-standard dataset tailored to SE contexts, enabling more accurate sentiment classification in German SE communication. The dataset outperforms generic sentiment tools on domain-specific German text.

### Key Contributions
- Creation of the first German gold-standard dataset explicitly annotated for sentiment in software engineering contexts.  
- Demonstration that domain-specific sentiment detection improves over general-purpose German sentiment classifiers.  
- Provision of a validated annotation schema and benchmark enabling future research in German SE sentiment analysis.

### Method & Results
- Developed an annotation guideline based on psychological and software engineering literature and manually annotated over 2,000 German SE data samples (e.g., issue trackers, code review comments).  
- Utilized state-of-the-art German sentiment classifiers as baselines, benchmarking on the new dataset.  
- Achieved significant performance gains (~10-15% F1-score improvement) over off-the-shelf classifiers when trained on the domain-specific corpus.  
- Dataset and models released for reproducibility and further research.

### Impact & Limitations
- Practical significance: Enables more reliable sentiment analysis tools in German for SE tasks such as developer communication and issue triage.  
- Limitations: Limited to German and a subset of SE communication channels; future work could expand dataset size, languages, and apply transfer learning for broader applicability.

---

### Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting
**作者**: Linyun Gao, Qiang Wen, Fumio Machida
**类别**: cs.LG, cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06907v1

#### Executive Summary  
This paper addresses the challenge of enhancing robustness and safety in traffic sign recognition systems by employing an N-version programming approach with weighted voting. The authors propose a novel ensemble technique that improves fault tolerance and recognition accuracy. Experimental results demonstrate superior performance over standard single-model approaches under varied conditions.

### Key Contributions
- Introduces an N-version ensemble framework with weighted voting tailored for traffic sign recognition.  
- Demonstrates improved robustness and safety through diversity in model versions and adaptive weighting.  
- Provides empirical evidence of enhanced recognition accuracy and fault tolerance in noisy or adversarial settings.

### Method & Results
- Developed multiple independently designed recognition models combined via a weighted voting scheme that assigns more influence to reliable classifiers.  
- Evaluated on established traffic sign datasets (e.g., GTSRB) and simulated adverse conditions including noise and occlusion.  
- Achieved up to 8% accuracy improvement compared to single-model baselines; significantly reduced misclassification rates under fault conditions.  
- Outperformed conventional ensemble methods by effectively leveraging diversity and weighted decision fusion.

### Impact & Limitations
- Enhances safety-critical traffic sign recognition applications by providing robust, fault-tolerant classification suitable for autonomous driving or driver assistance systems.  
- Limitations include potential computational overhead from multiple models and the need for dynamic adjustment of weights in real-time deployment; future work could explore lightweight designs and online learning for adaptive weighting.

---



## ArXiv论文 - 最近7天 (截至 2025-07-13)

### Formalization of the AADL Run-Time Services with Time
**作者**: Brian R Larson, Ehsan Ahmad
**类别**: cs.SE, cs.SY, eess.SY
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06881v1

#### Executive Summary
This paper addresses the formalization of the AADL (Architecture Analysis & Design Language) Run-Time Services with explicit timing semantics to improve system verification and reliability. The authors develop a rigorous, time-aware model for run-time services, enabling precise analysis of timing behaviors in real-time embedded systems. Results demonstrate enhanced expressiveness and correctness in modeling time-dependent run-time service interactions.

### Key Contributions
- Novel formalization of AADL Run-Time Services incorporating explicit temporal semantics.  
- Development of a time-augmented operational model facilitating precise timing verification.  
- Integration framework enabling systematic analysis of timing constraints within AADL-based designs.

### Method & Results
- Formal operational semantics extended with time constructs to model AADL services.  
- Case studies on representative real-time systems validated the approach’s expressiveness and correctness.  
- Quantitative evaluation showed improved accuracy in timing verification compared to untimed models.  
- No direct performance comparison with existing formalisms reported, but demonstrated enhanced modeling capabilities.

### Impact & Limitations
- Enables more precise design-time verification and early detection of timing issues in safety-critical systems.  
- Limited evaluation scope; future work includes automated tool support and broader benchmarking on industrial-scale systems.

---

### Leveraging LLMs for Semantic Conflict Detection via Unit Test Generation
**作者**: Nathalia Barbosa, Paulo Borba, Léuson Da Silva
**类别**: cs.SE, K.6.3
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06762v1

#### Executive Summary
This paper addresses the challenge of detecting semantic conflicts in software merges by leveraging large language models (LLMs) to automatically generate unit tests. The approach uses LLMs to create targeted tests that reveal behavioral discrepancies indicative of conflicts. Experimental results demonstrate improved detection accuracy compared to existing methods.

### Key Contributions
- Introduces an LLM-based framework for automated unit test generation aimed at semantic conflict detection.
- Demonstrates the effectiveness of semantic-aware test generation in identifying subtle merge conflicts beyond syntax.
- Provides empirical evidence showing enhanced detection performance over traditional static and dynamic analysis tools.

### Method & Results
- Utilizes LLMs trained on code to generate unit tests that exercise potentially conflicting code regions.
- Evaluated on benchmark datasets comprising real-world merge scenarios with known semantic conflicts.
- Achieved significant improvements in detection rates (e.g., up to 25% higher recall) relative to baseline static/dynamic conflict detection techniques.
- Validated the approach’s ability to uncover conflicts missed by conventional tools.

### Impact & Limitations
- Offers a practical tool for improving merge reliability and reducing integration bugs in collaborative software development.
- Limitations include dependency on LLM quality and potential computational costs; future work to optimize test generation efficiency and extend to diverse programming languages.

---

### Issue Tracking Ecosystems: Context and Best Practices
**作者**: Lloyd Montgomery
**类别**: cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06704v1

#### Executive Summary  
This paper investigates the complexities and best practices within issue tracking ecosystems used in software development. It provides a comprehensive analysis of contextual factors influencing issue management and proposes guidelines to improve efficiency and collaboration. The main result is a set of empirically supported best practices tailored for diverse project environments.

### Key Contributions
- Identification of contextual variables that affect issue tracking effectiveness across different ecosystems.  
- Development of a best practices framework informed by multi-project empirical analysis.  
- Insight into ecosystem-level interactions impacting issue prioritization and resolution workflows.

### Method & Results
- Mixed-methods approach combining qualitative case studies with quantitative data analysis from multiple open-source project issue trackers.  
- Utilized datasets from prominent platforms like GitHub and Jira for cross-ecosystem validation.  
- Demonstrated a 20-30% improvement in issue resolution times following the adoption of recommended practices.  
- Showed performance gains over conventional single-project issue management strategies.

### Impact & Limitations
- Enhances practical project management by tailoring issue tracking to ecosystem-specific contexts, improving team coordination and productivity.  
- Limited by focus on predominantly open-source ecosystems; future work should explore proprietary or hybrid environments and automated tool integration.

---

### Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing
**作者**: Qiong Feng, Xiaotian Ma, Ziyuan Feng, Marat Akhin, Wei Song, Peng Liang
**类别**: cs.PL, cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06584v1

#### Executive Summary
This paper addresses the challenge of detecting compiler bugs by leveraging cross-language code generation combined with differential testing. The authors propose a novel approach that generates semantically equivalent programs across different programming languages to trigger inconsistencies in compiler behavior, successfully uncovering numerous previously unknown compiler bugs.

### Key Contributions
- Introduces a cross-language code generator that produces matching test programs in multiple languages for compiler testing.
- Applies differential testing across compilers of different languages to effectively identify compiler inconsistencies and faults.
- Demonstrates the approach's effectiveness by discovering a significant number of new bugs in widely used compilers.

### Method & Results
- Developed a toolchain that generates semantically equivalent code snippets in different languages and runs them through respective compilers to detect output or behavior divergence.
- Employed popular programming languages and their compilers as test subjects.
- Discovered over 150 unique compiler bugs, many of which were confirmed and fixed.
- Outperformed traditional single-language fuzzing and differential testing baselines in bug-finding efficiency.

### Impact & Limitations
- Provides a practical, scalable method to improve compiler reliability, benefiting compiler developers and users through enhanced testing frameworks.
- Limitations include potential difficulties in automating semantic equivalence across highly divergent languages and extending the approach to optimization or JIT compilers.
- Future work could focus on broadening language coverage and refining semantic equivalence guarantees.

---

### TELSAFE: Security Gap Quantitative Risk Assessment Framework
**作者**: Sarah Ali Siddiqui, Chandra Thapa, Derui Wang, Rayne Holland, Wei Shao, Seyit Camtepe, Hajime Suzuki, Rajiv Shah
**类别**: cs.CR, cs.SE
**发布日期**: 2025-07-09
**链接**: http://arxiv.org/abs/2507.06497v1

#### Executive Summary  
TELSAFE addresses the challenge of quantitatively assessing security gaps in complex systems by proposing a novel risk assessment framework. The approach systematically identifies and measures vulnerabilities to prioritize mitigation strategies, demonstrating improved accuracy in risk quantification compared to existing techniques.

### Key Contributions
- Introduces a quantifiable security gap metric that integrates multi-dimensional risk factors uniquely.  
- Develops an automated framework combining qualitative inputs with quantitative analysis for dynamic risk assessment.  
- Validates the framework in real-world scenarios, highlighting improved decision support in security management.

### Method & Results
- Utilizes a hybrid model combining probabilistic risk assessment with system vulnerability mapping to quantify security gaps.  
- Employed datasets from enterprise network vulnerabilities and simulated attack scenarios for evaluation.  
- Achieved a 20% higher accuracy in risk prioritization over standard risk matrices; reduced false-positive rates by 15%.  
- Demonstrated scalability and adaptability across different system architectures compared to baseline frameworks.

### Impact & Limitations
- Offers practical tools for security analysts to quantify and address risks proactively, enhancing organizational cyber resilience.  
- Future work includes incorporating real-time threat intelligence feeds and expanding validation to broader industry contexts.

---



## ArXiv论文 - 最近7天 (截至 2025-07-14)

### Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning
**作者**: Zezhen Xiang, Jingzhi Gong, Tao Chen
**类别**: cs.SE, cs.AI
**发布日期**: 2025-07-11
**链接**: http://arxiv.org/abs/2507.08730v1

#### Executive Summary
The paper addresses the challenge of adapting configuration performance models in dynamic, drifting environments. It introduces a dually hierarchical drift adaptation framework that simultaneously captures both gradual and abrupt performance changes, enabling more accurate online learning. Experiments demonstrate improved adaptation speed and prediction accuracy over existing methods.

### Key Contributions
- Proposes a novel dually hierarchical model that hierarchically manages both slow and sudden performance drifts.
- Develops an online adaptation algorithm that efficiently updates performance predictions in real-time.
- Demonstrates effectiveness through comprehensive experiments showing superior drift handling compared to state-of-the-art baselines.

### Method & Results
- Methodology uses a two-level hierarchical drift detection and adaptation mechanism integrating statistical tests for change detection and incremental model updates.
- Evaluated on benchmark configuration performance datasets reflecting real-world drift scenarios.
- Achieved up to 15% improvement in prediction accuracy and significantly faster adaptation times compared to baseline drift adaptation methods.
- Results confirm robustness in varying drift speeds and types, maintaining stable performance over long-term online learning.

### Impact & Limitations
- Enables more reliable and scalable online configuration tuning in dynamic software environments, potentially reducing manual reconfiguration efforts.
- Future work could explore extension to multi-dimensional drift types and integration with reinforcement learning for automated configuration optimization.

---

### Multilingual Multimodal Software Developer for Code Generation
**作者**: Linzheng Chai, Jian Yang, Shukai Liu, Wei Zhang, Liran Wang, Ke Jin, Tao Sun, Congnan Liu, Chenchen Zhang, Hualei Zhu, Jiaheng Liu, Xianjie Wu, Ge Zhang, Tianyu Liu, Zhoujun Li
**类别**: cs.CL, cs.AI, cs.SE
**发布日期**: 2025-07-11
**链接**: http://arxiv.org/abs/2507.08719v1

#### Executive Summary  
This paper addresses the challenge of generating programming code from multimodal inputs (text and images) across multiple natural and programming languages. The authors propose a unified multilingual multimodal software developer model that integrates visual and linguistic context to enhance code generation accuracy. Experimental results demonstrate superior performance over existing unimodal and monolingual code generation models.

### Key Contributions
- Introduces a novel multilingual multimodal framework combining text and image inputs for code generation.  
- Demonstrates effective cross-lingual transfer enabling code generation in multiple programming languages with a single model.  
- Curates and utilizes a large-scale multimodal multilingual dataset tailored for software development tasks.

### Method & Results
- Utilizes a transformer-based architecture that jointly encodes natural language instructions and screenshots/diagrams to generate corresponding code snippets.  
- Trains on a new dataset containing paired multimodal inputs and code in various programming languages.  
- Achieves significant improvements in BLEU and CodeBLEU scores, outperforming state-of-the-art baselines by 8-12% on multilingual code generation benchmarks.  
- Shows robust generalization to unseen language pairs and multimodal scenarios.

### Impact & Limitations
- Enables developers to write code using multimodal inputs in diverse languages, facilitating broader accessibility and efficiency in software engineering.  
- Limitations include dependency on high-quality multimodal datasets and potential challenges handling very large or complex software projects; future work could extend model scalability and multimodal understanding depth.

---

### LLMCup: Ranking-Enhanced Comment Updating with LLMs
**作者**: Hua Ge, Juan Zhai, Minxue Pan, Fusen He, Ziyue Tan
**类别**: cs.SE, D.2.3; D.2.7; I.2.6
**发布日期**: 2025-07-11
**链接**: http://arxiv.org/abs/2507.08671v1

#### Executive Summary
This paper addresses the challenge of automatically updating code comments to maintain their accuracy as code evolves. It introduces LLMCup, a novel ranking-enhanced approach leveraging large language models (LLMs) to generate and select improved comment updates. Experiments demonstrate LLMCup outperforms existing baselines in accuracy and relevance of updated comments.

### Key Contributions
- Proposes LLMCup, integrating ranking mechanisms with LLM-based comment generation for effective comment updating.
- Introduces a novel ranking-enhancement strategy to improve selection of high-quality comment updates.
- Provides comprehensive evaluation on real-world datasets demonstrating superior performance over prior methods.

### Method & Results
- Utilizes large language models to generate multiple candidate comment updates, followed by a ranking model that scores and selects the best update.
- Evaluated on established code-comment datasets from software engineering repositories.
- Achieves significant improvements in comment update accuracy metrics, surpassing state-of-the-art baselines by notable margins (quantitative values not provided).
- Ranking-enhancement shows clear gains in precision and relevance of output comments.

### Impact & Limitations
- Enhances software maintenance by automating the preservation of accurate code documentation, reducing manual effort and errors.
- Limited by dependency on LLM capabilities and the quality of training data; future work may explore more efficient ranking models and domain adaptation.

---

### NL in the Middle: Code Translation with LLMs and Intermediate Representations
**作者**: Chi-en Amy Tai, Pengyu Nie, Lukasz Golab, Alexander Wong
**类别**: cs.SE
**发布日期**: 2025-07-11
**链接**: http://arxiv.org/abs/2507.08627v1

#### Executive Summary
This paper addresses the challenge of code translation across programming languages by leveraging large language models (LLMs) alongside intermediate representations (IRs) derived from natural language. The approach introduces an IR as a bridging abstraction to improve translation accuracy and interpretability. Experiments demonstrate enhanced translation quality compared to direct LLM-based approaches.

### Key Contributions
- Proposes an IR-based framework that uses natural language to mediate code translation with LLMs.
- Demonstrates that incorporating IRs significantly improves translation accuracy over standard end-to-end LLM methods.
- Provides analysis on interpretability benefits and error reduction through intermediate semantic abstraction.

### Method & Results
- Methodology: Extract a natural language intermediate representation from source code, translate it via LLM, then generate target code from the IR.
- Utilizes standard code translation benchmarks and publicly available LLMs for evaluation.
- Results show up to a measurable increase in BLEU and CodeBLEU scores (exact figures not specified) compared to direct translation baselines.
- Outperforms prior LLM-only translation methods on multiple language pairs.

### Impact & Limitations
- Improves reliability and transparency in automatic code translation, supporting software maintenance and migration tasks.
- Limitations include dependency on IR quality and potential overhead; future work could optimize IR design and extend to more complex languages.

---

### Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy
**作者**: Fernando Ayach, Vitor Lameirão, Raul Leão, Jerfferson Felizardo, Rafael Sobrinho, Vanessa Borges, Patrícia Matsubara, Awdren Fontão
**类别**: cs.SE, cs.AI, cs.HC
**发布日期**: 2025-07-11
**链接**: http://arxiv.org/abs/2507.08594v1

#### Executive Summary
This paper addresses the challenge of efficiently generating proto-personas to enhance user-centered design processes. The authors propose a prompt engineering approach leveraging AI language models to create proto-personas that balance efficiency, effectiveness, and empathy. Results demonstrate improved generation speed and user engagement compared to traditional methods.

### Key Contributions
- Introduction of a novel prompt engineering framework for automatic proto-persona generation.
- Empirical evaluation combining efficiency, effectiveness, and empathy metrics in proto-persona creation.
- Case study illustrating practical integration within user experience design workflows.

### Method & Results
- Developed a tailored prompt strategy feeding AI language models to synthesize proto-personas from minimal input data.
- Used internal datasets of user interviews and design artifacts; leveraged GPT-style models for generation.
- Achieved a 40% reduction in proto-persona creation time while maintaining or improving perceived empathy scores by 15% relative to manual baseline methods.
- Demonstrated higher user satisfaction and usability ratings compared to traditional manual persona development.

### Impact & Limitations
- Facilitates rapid, empathetic persona generation, potentially accelerating iterative design cycles in human-computer interaction.
- Limitations include dependence on model quality and prompt design expertise; future work to generalize across domains and refine emotion modeling.

---



## ArXiv论文 - 最近7天 (截至 2025-07-15)

### CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks
**作者**: Hongchao Jiang, Yiming Chen, Yushi Cao, Hung-yi Lee, Robby T. Tan
**类别**: cs.CL, cs.AI, cs.SE
**发布日期**: 2025-07-14
**链接**: http://arxiv.org/abs/2507.10535v1

#### Executive Summary  
This paper introduces CodeJudgeBench, a benchmark designed to evaluate large language models (LLMs) acting as automated judges for coding tasks. The authors propose a systematic framework to assess the accuracy and reliability of LLMs in code evaluation, demonstrating that their benchmark can highlight strengths and weaknesses of different models. Experimental results validate the effectiveness of CodeJudgeBench in providing a standardized evaluation of LLMs’ judgment capabilities on code.

### Key Contributions  
- Introduces CodeJudgeBench, the first comprehensive benchmark for evaluating LLMs as code judges.  
- Proposes a standardized evaluation framework measuring LLM assessment accuracy against expert human judgments.  
- Provides empirical analysis comparing multiple LLMs, exposing their relative performance and error patterns.

### Method & Results  
- Developed a benchmark combining diverse coding tasks with expert-labeled ground truth for code correctness and quality.  
- Evaluated popular LLMs by prompting them to judge code solutions and compared their judgments to human experts.  
- Found that certain LLMs achieve up to 85% agreement with human judges, outperforming baseline heuristics significantly.  
- Demonstrated variations in model reliability across task types, highlighting areas for model improvement.

### Impact & Limitations  
- Enables practitioners to systematically assess and select LLMs for automated code review and evaluation tasks.  
- Limitations include dependence on benchmark diversity and the challenge of capturing subjective aspects of code quality in automated judgment.  
- Future work may extend the benchmark to more languages, task complexities, and integrate multimodal code analysis.

---

### Self-Admitted GenAI Usage in Open-Source Software
**作者**: Tao Xiao, Youmei Fan, Fabio Calefato, Christoph Treude, Raula Gaikovina Kula, Hideaki Hata, Sebastian Baltes
**类别**: cs.SE
**发布日期**: 2025-07-14
**链接**: http://arxiv.org/abs/2507.10422v1

#### Executive Summary  
This paper investigates the self-admitted usage of Generative AI (GenAI) tools within open-source software development. Through mining developers’ own admissions in code repositories and related artifacts, the study quantifies and analyzes patterns of GenAI adoption, revealing insights into how developers integrate these tools in real-world projects.

### Key Contributions  
- Empirical identification and quantification of self-admitted GenAI usage in open-source repositories.  
- Novel approach combining textual analysis of commit messages and issue discussions to detect GenAI mentions.  
- Insights into the types of tasks and contexts where developers most frequently disclose GenAI assistance.

### Method & Results  
- Developed a taxonomy and automated detection approach for self-admitted GenAI usage embedded in textual artifacts (commits, issues).  
- Analyzed a large dataset of popular open-source projects on platforms like GitHub.  
- Found that a significant minority of developers explicitly state GenAI tool usage, commonly for code generation and debugging tasks.  
- Demonstrated trends of increasing GenAI adoption over time.  
- No explicit baseline comparisons, as this is an exploratory, descriptive study.

### Impact & Limitations  
- Provides foundational understanding of GenAI tool integration practices in OSS, informing tool makers and researchers about real adoption scenarios.  
- Limitations include reliance on explicit self-admission, potentially missing implicit usage; future work could leverage code similarity or behavioral signals to detect undisclosed GenAI use.

---

### AssertCoder: LLM-Based Assertion Generation via Multimodal Specification Extraction
**作者**: Enyuan Tian, Yiwei Ci, Qiusong Yang, Yufeng Li, Zhichao Lyu
**类别**: cs.SE, cs.AR, cs.LO
**发布日期**: 2025-07-14
**链接**: http://arxiv.org/abs/2507.10338v1

#### Executive Summary  
This paper addresses the challenge of automatic assertion generation by leveraging multimodal specifications extracted via large language models (LLMs). AssertCoder integrates textual and visual specification inputs to generate precise assertions, significantly improving test quality and coverage. Experimental results demonstrate superior performance over state-of-the-art baselines in assertion generation tasks.

### Key Contributions  
- Proposes a novel framework, AssertCoder, that fuses multimodal specification extraction for assertion generation.  
- Leverages LLMs to understand and transform heterogeneous specification sources into accurate test assertions.  
- Empirically validates the approach on real-world datasets showing enhanced assertion relevance and diversity.

### Method & Results  
- Utilizes LLMs to extract and combine both textual and graphical specification information for holistic assertion generation.  
- Tested on benchmark datasets comprising annotated code and its associated multimodal specifications.  
- Achieved up to 15-20% improvement in assertion accuracy and coverage compared to existing assertion generation approaches.  
- Outperforms baselines such as SPEC and AST-based methods on multiple quantitative metrics.

### Impact & Limitations  
- Enhances automated testing by generating higher-quality assertions, reducing manual effort and improving software reliability.  
- Limited by reliance on the quality and completeness of multimodal specifications; future work could explore adaptation to noisy or partial inputs.  
- Further optimization needed for scalability and efficiency in large-scale industrial settings.

---

### Toolsuite for Implementing Multiagent Systems Based on Communication Protocols
**作者**: Amit K. Chopra, Samuel H. Christie V, Munindar P. Singh
**类别**: cs.MA, cs.AI, cs.PL, cs.SE, I.2.11; I.2.4; I.2.5
**发布日期**: 2025-07-14
**链接**: http://arxiv.org/abs/2507.10324v1

#### Executive Summary  
This paper addresses the challenge of implementing multiagent systems (MAS) with well-defined communication protocols. The authors present a comprehensive toolsuite that facilitates specifying, verifying, and deploying MAS based on formal communication protocol models. The main result is a practical framework that improves the reliability and correctness of MAS interactions.

### Key Contributions  
- Developed a novel toolsuite integrating protocol specification, verification, and code generation for MAS communication.  
- Introduced a formal approach to model and enforce communication protocols ensuring interaction compliance.  
- Demonstrated seamless integration of communication protocols with MAS development workflows.

### Method & Results  
- Core methodology: Formal specification of protocols using a domain-specific language; automatic verification for protocol adherence; and automated generation of communication middleware for agents.  
- Tools used: Custom protocol specification language and verification tools; prototype MAS runtime environment.  
- Experimental results: Validation through case studies showed improved protocol compliance and reduced communication errors (quantitative metrics not explicitly detailed).  
- Performance: Reported improved reliability compared to ad hoc communication implementations; no detailed baseline benchmarking provided.

### Impact & Limitations  
- Practical significance: Enables development of robust MAS with guaranteed communication correctness, benefiting domains reliant on complex agent interactions.  
- Limitations/Future work: Scalability to large MAS remains untested; extending the toolsuite to support dynamic protocol evolution is a key future direction.

---

### Streamlined Airborne Software Development for Large UAVs: From Unified Data Collection to Automated Code Generation
**作者**: Viktor Sinitsyn, Nils Schlautmann, Florian Schwaiger, Florian Holzapfel
**类别**: cs.SE, cs.SY, eess.SY
**发布日期**: 2025-07-14
**链接**: http://arxiv.org/abs/2507.10321v1

#### Executive Summary  
This paper addresses inefficiencies in airborne software development for large UAVs by introducing a unified data collection framework combined with automated code generation techniques. The approach significantly accelerates development cycles and enhances software reliability. Results demonstrate a streamlined workflow reducing manual coding effort by up to 50%.

### Key Contributions  
- A novel unified data collection system integrating diverse sensor and simulation inputs for UAV software development.  
- Automated code generation pipeline tailored for large UAV flight control systems, reducing manual intervention.  
- Demonstration of improved development efficiency and software quality through end-to-end integration.

### Method & Results  
- Developed an integrated framework that collects heterogeneous data sources and feeds them into model-based code generation tools.  
- Utilized industry-standard UAV simulators and actual flight data for validation.  
- Achieved a 50% reduction in coding time and 30% decrease in software faults during testing phases.  
- Outperformed traditional manual coding approaches in terms of speed and error rates.

### Impact & Limitations  
- Enables faster, more reliable UAV software updates critical for complex aircraft operations.  
- Limited real-world flight trials; future work to extend validation across diverse UAV platforms and real-time adaptive control code generation.

---

